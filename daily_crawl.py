import json
import requests
import re
import time
import xml.etree.ElementTree as ET
from urllib.parse import quote

# --- ğŸ“¡ v2.0 æƒ…æŠ¥æºé…ç½® (ä¿®æ­£ç‰ˆ) ---
SOURCES = [
    {
        "category": "ç§‘æŠ€",
        "name": "ITä¹‹å®¶",
        "url": "https://www.ithome.com/rss/",
        "emoji": "âš¡",
        "max_items": 5
    },
    {
        "category": "è´¢ç»",
        "name": "æ–°æµªè´¢ç»", # æ›¿æ¢äº†ä¸ç¨³å®šçš„ 36æ°ª
        "url": "http://rss.sina.com.cn/roll/finance/hot_roll.xml", # è€ç‰Œç¨³å®šæº
        "emoji": "ğŸ“ˆ",
        "max_items": 5
    },
    {
        "category": "æ—¶äº‹",
        "name": "ä¸­æ–°ç½‘",
        "url": "http://www.chinanews.com.cn/rss/importnews.xml",
        "emoji": "ğŸ›ï¸",
        "max_items": 5
    }
]


# --- ğŸ§  AI é…ç½® ---
POLLINATIONS_URL = "https://text.pollinations.ai/{}"

def get_ai_summary(title, category):
    """æ ¹æ®æ–°é—»åˆ†ç±»ï¼Œè°ƒç”¨ AI ç”Ÿæˆä¸€å¥è¯æ€»ç»“"""
    try:
        # é’ˆå¯¹ä¸åŒåˆ†ç±»å¾®è°ƒ Prompt
        if category == "è´¢ç»":
            role = "financial analyst"
            focus = "identify market impact or investment signal"
        elif category == "æ—¶äº‹":
            role = "political commentator"
            focus = "summarize the core event objectively"
        else: # ç§‘æŠ€
            role = "tech editor"
            focus = "explain the innovation or impact"

        prompt = f"As a {role}, translate title to Chinese (if needed) and {focus} in 1 sentence (max 30 words). Title: '{title}'"
        
        target_url = POLLINATIONS_URL.format(quote(prompt))
        # ä½¿ç”¨ openai æ¨¡å‹ä»¥è·å¾—æ›´å¥½ç†è§£åŠ›
        response = requests.get(target_url + "?model=openai", timeout=20)
        
        if response.status_code == 200:
            return response.text.strip()
        else:
            return "AI æ­£åœ¨åˆ†æä¸­..."
    except:
        return "æš‚æ—  AI ç‚¹è¯„"

def fetch_rss_data(source_config):
    """é€šç”¨çš„ RSS æŠ“å–å‡½æ•°"""
    category = source_config['category']
    print(f"ğŸ“¡ æ­£åœ¨è¿æ¥ [{category}] {source_config['name']} ...")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        resp = requests.get(source_config['url'], headers=headers, timeout=15)
        resp.encoding = 'utf-8' # é˜²æ­¢ä¸­æ–‡ä¹±ç 
        
        if resp.status_code != 200:
            print(f"âŒ {category} æºè¿æ¥å¤±è´¥: {resp.status_code}")
            return []

        # è§£æ XML
        root = ET.fromstring(resp.text)
        channel = root.find('channel')
        items = channel.findall('item')[:source_config['max_items']] # é™åˆ¶æ¡æ•°

        results = []
        for item in items:
            title = item.find('title').text
            # è¿™é‡Œçš„ link ç•™ç€å¤‡ç”¨ï¼Œè™½ç„¶æˆ‘ä»¬åªå±•ç¤ºæ ‡é¢˜
            # link = item.find('link').text 
            
            print(f"   -> æŠ“å–: {title[:15]}...")
            
            # AI æ€»ç»“
            ai_text = get_ai_summary(title, category)
            # æ¸…æ´—
            ai_text = ai_text.replace("'", "").replace('"', '').replace("\n", "")
            if len(ai_text) > 50: ai_text = ai_text[:49] + "..."

            results.append({
                "title": title,
                "category": category,
                "emoji": source_config['emoji'],
                "aiReason": ai_text
            })
            
            # å…³é”®ï¼šé¿å…è¯·æ±‚è¿‡å¿«è¢« AI å°é”ï¼Œæ¯ä¸ªè¯·æ±‚é—´éš” 1.5 ç§’
            time.sleep(1.5)
            
        return results

    except Exception as e:
        print(f"âŒ {category} è§£æé”™è¯¯: {e}")
        return []

def main():
    print("ğŸš€ å¯åŠ¨å…¨ç½‘æƒ…æŠ¥èšåˆ (5x Daily)...")
    
    all_news = []
    
    # éå†æ‰€æœ‰æº
    for source in SOURCES:
        news_items = fetch_rss_data(source)
        all_news.extend(news_items)
        # æºä¸æºä¹‹é—´ä¼‘æ¯ 2 ç§’
        time.sleep(2)

    # å¦‚æœå®Œå…¨æ²¡æ•°æ®ï¼Œå°±ä¸æ›´æ–°
    if not all_news:
        print("âš ï¸ æœ¬æ¬¡æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼Œè·³è¿‡æ›´æ–°")
        return

    # ç”Ÿæˆ HTML æ•°æ®
    update_html(all_news)

def update_html(news_list):
    try:
        with open("index.html", "r", encoding="utf-8") as f:
            content = f.read()
        
        js_data = ""
        # èµ‹äºˆ ID
        for i, item in enumerate(news_list):
            # é¢œè‰²é€»è¾‘ï¼šä¸åŒåˆ†ç±»ç»™ä¸åŒçƒ­åº¦æ ‡ç­¾é¢œè‰²ï¼ˆé€šè¿‡ emoji åŒºåˆ†è§†è§‰ï¼‰
            # è¿™é‡Œå¤ç”¨ä¹‹å‰çš„ç»“æ„
            js_data += "                {\n"
            js_data += f"                    id: {i}, platform: '{item['category']}', title: '{item['title']}', price: 'News', sales: 'åˆšåˆš', score: {100-i}, emoji: '{item['emoji']}',\n"
            js_data += f"                    aiReason: '{item['aiReason']}'\n"
            js_data += "                },\n"

        pattern = r"(// DATA_START\n)(.*?)(// DATA_END)"
        if re.search(pattern, content, re.DOTALL):
            new_content = re.sub(pattern, f"\\1{js_data}                \\3", content, flags=re.DOTALL)
            with open("index.html", "w", encoding="utf-8") as f:
                f.write(new_content)
            print(f"ğŸ‰ æˆåŠŸæ›´æ–° {len(news_list)} æ¡æƒ…æŠ¥ï¼")
    except Exception as e:
        print(f"âŒ HTML å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()


