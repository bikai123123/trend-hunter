import json
import requests
import re
import time
from urllib.parse import quote

# --- é…ç½®åŒº ---
HN_TOP_URL = "https://hacker-news.firebaseio.com/v0/topstories.json"
HN_ITEM_URL = "https://hacker-news.firebaseio.com/v0/item/{}.json"

# Pollinations AI (å… Keyï¼Œå…è´¹ï¼Œæ— é™åˆ¶æ¥å£)
# åŸç†ï¼šç›´æ¥é€šè¿‡ URL ä¼ å‚è·å– AI å“åº”
POLLINATIONS_URL = "https://text.pollinations.ai/{}"

def get_ai_insight(title):
    """è°ƒç”¨ Pollinations AI ç”Ÿæˆä¸­æ–‡çŸ­è¯„"""
    try:
        # 1. æ„é€  Prompt
        # è¦æ±‚ï¼šç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶ç”¨ä¸€å¥è¯ï¼ˆ30å­—å†…ï¼‰çŠ€åˆ©ç‚¹è¯„
        prompt = f"Translate the following Hacker News title to Chinese and explain why it is interesting in 1 sentence (max 30 words, professional tone): '{title}'"
        
        # 2. URL ç¼–ç  (å¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦)
        safe_prompt = quote(prompt)
        target_url = POLLINATIONS_URL.format(safe_prompt)
        
        # 3. å‘é€ GET è¯·æ±‚ (Pollinations æå…¶ç®€å•ï¼Œç›´æ¥ GET å³å¯)
        # å¢åŠ  model=openai å‚æ•°è¯•å›¾è·å–æ›´é«˜è´¨é‡å›ç­”ï¼Œä¹Ÿå¯ä»¥ä¸åŠ 
        response = requests.get(target_url + "?model=openai", timeout=15)
        
        if response.status_code == 200:
            return response.text.strip()
        else:
            return f"çƒ­åº¦: High (AI æ¥å£ {response.status_code})"
            
    except Exception as e:
        print(f"âš ï¸ AI è¯·æ±‚å¤±è´¥: {e}")
        return "AI è¿æ¥è¶…æ—¶"

def fetch_hn_data():
    print("ğŸš€ å¯åŠ¨ (Pollinations æ— é™åˆ¶ç‰ˆ)...")
    
    try:
        # æ¢å¤åˆ°æŠ“å– 8 æ¡ï¼å› ä¸ºæ²¡æœ‰é…é¢é™åˆ¶äº†ï¼
        top_ids = requests.get(HN_TOP_URL, timeout=10).json()[:8]
        
        products = []
        for i, item_id in enumerate(top_ids):
            item = requests.get(HN_ITEM_URL.format(item_id), timeout=5).json()
            title = item.get('title', 'No Title').replace("'", "\\'")
            score = item.get('score', 0)
            
            print(f"[{i+1}/8] åˆ†æ: {title[:20]}...")
            
            # è°ƒç”¨ AI
            ai_reason = get_ai_insight(title)
            
            # æ¸…æ´—æ•°æ® (é˜²æ­¢ AI è¿”å› Markdown æ ¼å¼æˆ–å¼•å·ç ´å JS)
            ai_reason = ai_reason.replace("'", "").replace('"', '').replace("\n", "")
            # å¦‚æœ AI è¿”å›å¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
            if len(ai_reason) > 50: ai_reason = ai_reason[:49] + "..."

            # Emoji é€»è¾‘
            emoji = "ğŸ“°"
            if "show hn" in title.lower(): emoji = "ğŸš€"
            elif "ai" in title.lower(): emoji = "ğŸ¤–"
            elif "google" in title.lower(): emoji = "ğŸ”"

            products.append({
                "id": item_id, "platform": "HackerNews", "title": title,
                "price": "Free", "sales": f"{score} ğŸ”¥", "score": score,
                "emoji": emoji, "aiReason": ai_reason
            })
            
            # è™½ç„¶æ— é™åˆ¶ï¼Œä½†è¿˜æ˜¯ç¤¼è²Œæ€§åœé¡¿ 1 ç§’ï¼Œé˜²æ­¢ç½‘ç»œå µå¡
            time.sleep(1)
            
        return products
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return []

def update_html(new_data):
    if not new_data: return
    try:
        with open("index.html", "r", encoding="utf-8") as f: content = f.read()
        
        js_data = ""
        for p in new_data:
            js_data += "                {\n"
            js_data += f"                    id: {p['id']}, platform: '{p['platform']}', title: '{p['title']}', price: '{p['price']}', sales: '{p['sales']}', score: {p['score']}, emoji: '{p['emoji']}',\n"
            js_data += f"                    aiReason: '{p['aiReason']}'\n"
            js_data += "                },\n"

        pattern = r"(// DATA_START\n)(.*?)(// DATA_END)"
        if re.search(pattern, content, re.DOTALL):
            new_content = re.sub(pattern, f"\\1{js_data}                \\3", content, flags=re.DOTALL)
            with open("index.html", "w", encoding="utf-8") as f: f.write(new_content)
            print("ğŸ‰ æ›´æ–°æˆåŠŸï¼")
    except: pass

if __name__ == "__main__":
    data = fetch_hn_data()
    update_html(data)
