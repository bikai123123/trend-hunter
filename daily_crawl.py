import json
import requests
import re
import time
import xml.etree.ElementTree as ET
from urllib.parse import quote

# --- ğŸ“¡ v3.3 åŒä¿é™©ç¨³å®šæº ---
SOURCES = [
    {
        "category": "ç§‘æŠ€",
        "name": "ITä¹‹å®¶",
        "url": "https://www.ithome.com/rss/",
        "emoji": "âš¡",
        "max_items": 20
    },
    {
        "category": "è´¢ç»",
        "name": "ä¸­æ–°è´¢ç»", # ã€æ›¿æ¢ã€‘æ”¹ç”¨å’Œæ—¶äº‹ä¸€æ ·çš„æºï¼Œç¡®ä¿èƒ½è¿é€š
        "url": "http://www.chinanews.com.cn/rss/finance.xml", 
        "emoji": "ğŸ’°",
        "max_items": 20
    },
    {
        "category": "æ—¶äº‹",
        "name": "ä¸­æ–°è¦é—»",
        "url": "http://www.chinanews.com.cn/rss/importnews.xml",
        "emoji": "ğŸ›ï¸",
        "max_items": 20
    }
]

# --- ğŸ§  AI åˆ†æå†…æ ¸ ---
POLLINATIONS_URL = "https://text.pollinations.ai/{}"

def get_ai_summary(title, category):
    """AI æé€Ÿæ€»ç»“"""
    try:
        if category == "è´¢ç»":
            prompt = f"As a financial analyst, summarize market impact in 1 sentence (Chinese). Title: '{title}'"
        elif category == "æ—¶äº‹":
            prompt = f"Summarize event objectively in 1 sentence (Chinese). Title: '{title}'"
        else:
            prompt = f"Explain tech innovation in 1 sentence (Chinese). Title: '{title}'"
        
        # å¢åŠ  model=openai å‚æ•°ï¼Œå¹¶å¯¹ prompt è¿›è¡Œ URL ç¼–ç 
        target_url = POLLINATIONS_URL.format(quote(prompt))
        response = requests.get(target_url + "?model=openai", timeout=8) # ç¼©çŸ­è¶…æ—¶ï¼ŒåŠ é€Ÿ
        
        if response.status_code == 200:
            return response.text.strip()
        return "ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…"
    except:
        return "ç‚¹å‡»é˜…è¯»åŸæ–‡"

def fetch_rss_data(source_config):
    """RSS æŠ“å–å¼•æ“ (æ™ºèƒ½ç¼–ç ç‰ˆ)"""
    category = source_config['category']
    print(f"ğŸ“¡ è¿æ¥ [{category}] {source_config['name']}...")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        resp = requests.get(source_config['url'], headers=headers, timeout=15)
        
        if resp.status_code != 200:
            print(f"âŒ è¿æ¥å¤±è´¥: {resp.status_code}")
            return []

        # --- æ™ºèƒ½ç¼–ç å¤„ç† ---
        # å…ˆå°è¯•è‡ªåŠ¨è¯†åˆ«ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ° utf-8ï¼Œæœ€åå°è¯• gbk
        content_decoded = ""
        try:
            # ä¼˜å…ˆä½¿ç”¨ response æ¨æµ‹çš„ç¼–ç ï¼Œå¦‚æœä¸ºç©ºåˆ™é»˜è®¤ utf-8
            encoding = resp.encoding if resp.encoding else 'utf-8'
            content_decoded = resp.content.decode(encoding, errors='replace')
        except:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šGBK (å¸¸è§äºè€æ—§ä¸­æ–‡ç«™)
            try:
                content_decoded = resp.content.decode('gbk', errors='replace')
            except:
                # æœ€åçš„æŒ£æ‰ï¼šå¿½ç•¥é”™è¯¯å¼ºåˆ¶è§£ç 
                content_decoded = resp.content.decode('utf-8', errors='ignore')

        # è§£æ XML
        root = ET.fromstring(content_decoded)
        channel = root.find('channel')
        items = channel.findall('item')[:source_config['max_items']]

        results = []
        for i, item in enumerate(items):
            title = item.find('title').text
            link = item.find('link').text
            
            # è¿›åº¦æ¡
            if i % 5 == 0: print(f"   -> {category} ({i+1}/{source_config['max_items']}): {title[:8]}...")
            
            ai_text = get_ai_summary(title, category)
            # æ¸…æ´—æ•°æ®
            ai_text = ai_text.replace("'", "").replace('"', '').replace("\n", "")
            if len(ai_text) > 40: ai_text = ai_text[:39] + "..."

            results.append({
                "title": title,
                "link": link,
                "category": category,
                "emoji": source_config['emoji'],
                "aiReason": ai_text
            })
            
            # ç¨å¾®å¿«ä¸€ç‚¹ï¼Œ0.5ç§’é—´éš”
            time.sleep(0.5)
            
        return results

    except Exception as e:
        print(f"âŒ è§£æé”™è¯¯ ({category}): {e}")
        return []

def update_html(news_list):
    if not news_list: return
    try:
        with open("index.html", "r", encoding="utf-8") as f:
            content = f.read()
        
        js_data = ""
        for i, item in enumerate(news_list):
            js_data += "                {\n"
            js_data += f"                    id: {i}, platform: '{item['category']}', title: '{item['title']}', link: '{item['link']}', price: 'News', sales: 'åˆšåˆš', score: {100-i}, emoji: '{item['emoji']}',\n"
            js_data += f"                    aiReason: '{item['aiReason']}'\n"
            js_data += "                },\n"

        pattern = r"(// DATA_START\n)(.*?)(// DATA_END)"
        if re.search(pattern, content, re.DOTALL):
            new_content = re.sub(pattern, f"\\1{js_data}                \\3", content, flags=re.DOTALL)
            with open("index.html", "w", encoding="utf-8") as f:
                f.write(new_content)
            print(f"ğŸ‰ æˆåŠŸæ›´æ–° {len(news_list)} æ¡æƒ…æŠ¥ï¼")
    except Exception as e:
        print(f"âŒ HTML å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    all_news = []
    for source in SOURCES:
        data = fetch_rss_data(source)
        all_news.extend(data)
        time.sleep(1)
    update_html(all_news)
