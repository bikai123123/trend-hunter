import json
import requests
import re
import time
import xml.etree.ElementTree as ET
from urllib.parse import quote

# --- é…ç½®åŒº ---
# ä»€ä¹ˆå€¼å¾—ä¹° (Smzdm) å®˜æ–¹ RSS æº
# å›½å†…ç²¾é€‰: https://feed.smzdm.com/guonei/
# å‘ç°é¢‘é“: https://feed.smzdm.com/faxian/
SMZDM_RSS_URL = "https://feed.smzdm.com/guonei/"

# Pollinations AI (å…è´¹ã€å›½å†…å¯ç”¨)
POLLINATIONS_URL = "https://text.pollinations.ai/{}"

def get_ai_insight(title, description):
    """ç”¨ AI åˆ†æä¸­æ–‡å•†å“"""
    try:
        # è¿™é‡Œçš„ description é€šå¸¸åŒ…å«ä»·æ ¼ä¿¡æ¯ï¼Œå¾ˆæœ‰ç”¨
        clean_desc = description[:50].replace('<br>', '')
        
        # æ„é€  Prompt: è§’è‰²æ˜¯ç”µå•†é€‰å“ä¸“å®¶
        prompt = f"åˆ†æè¿™æ¬¾ä¸­å›½ç”µå•†çƒ­é—¨å•†å“ã€‚ç”¨ä¸€å¥è¯ï¼ˆ30å­—å†…ï¼‰çŠ€åˆ©ç‚¹è¯„å®ƒçš„å–ç‚¹æˆ–ä»·æ ¼ä¼˜åŠ¿ã€‚å•†å“: '{title}'ã€‚è¯¦æƒ…: '{clean_desc}'"
        
        target_url = POLLINATIONS_URL.format(quote(prompt))
        # å¢åŠ  model=openai å‚æ•°ï¼Œè·å–æ›´å¥½è´¨é‡
        response = requests.get(target_url + "?model=openai", timeout=20)
        
        if response.status_code == 200:
            return response.text.strip()
        else:
            return "çƒ­åº¦æé«˜ (AI åˆ†ææš‚ç¼º)"
            
    except Exception as e:
        print(f"âš ï¸ AI é”™è¯¯: {e}")
        return "è¶…å€¼å¥½ä»·"

def fetch_domestic_data():
    print("ğŸš€ å¯åŠ¨å›½å†…ç”µå•†é›·è¾¾ (Smzdm RSS)...")
    
    # æ¨¡æ‹Ÿæµè§ˆå™¨ User-Agentï¼Œé˜²æ­¢ RSS æ¥å£æ‹’ç» GitHub IP
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }

    try:
        response = requests.get(SMZDM_RSS_URL, headers=headers, timeout=15)
        # å¼ºåˆ¶è®¾ç½®ç¼–ç ï¼Œé˜²æ­¢ä¸­æ–‡ä¹±ç 
        response.encoding = 'utf-8' 
        
        if response.status_code != 200:
            print(f"âŒ æ— æ³•è¿æ¥æºç«™: {response.status_code}")
            return []

        # è§£æ XML
        root = ET.fromstring(response.text)
        channel = root.find('channel')
        items = channel.findall('item')[:8] # å–å‰ 8 æ¡

        products = []
        for i, item in enumerate(items):
            title = item.find('title').text
            # ä»·æ ¼é€šå¸¸åœ¨ title é‡Œï¼Œæˆ–è€… description é‡Œ
            description = item.find('description').text
            link = item.find('link').text
            
            print(f"[{i+1}/8] å‘ç°: {title[:15]}...")
            
            # AI åˆ†æ
            ai_reason = get_ai_insight(title, description)
            # æ¸…æ´—æ–‡æ¡ˆ
            ai_reason = ai_reason.replace("'", "").replace('"', '').replace("\n", "")

            # ç®€å•çš„å…³é”®è¯ Emoji
            emoji = "ğŸ"
            if "ç”µè„‘" in title or "Apple" in title or "æ‰‹æœº" in title: emoji = "ğŸ’»"
            elif "é…’" in title: emoji = "ğŸº"
            elif "é‹" in title or "è¡£" in title: emoji = "ğŸ‘•"
            elif "åˆ¸" in title: emoji = "ğŸ«"

            # æå–ä»·æ ¼ (ç²—ç•¥æå–)
            price = "å¥½ä»·"
            # å°è¯•ä»æ ‡é¢˜æå–æ•°å­— (æ¯”å¦‚ "199å…ƒ")
            price_match = re.search(r'(\d+(?:\.\d+)?)(å…ƒ|kw|ä¸‡)', title)
            if price_match:
                price = price_match.group(0)

            products.append({
                "id": i + 888, 
                "platform": "ä»€ä¹ˆå€¼å¾—ä¹°", # æ ‡è®°æ¥æº
                "title": title, 
                "price": price, 
                "sales": "ğŸ”¥ Hot", 
                "score": 99 - i, 
                "emoji": emoji, 
                "aiReason": ai_reason
            })
            
            time.sleep(2) # ç¤¼è²ŒæŠ“å–
            
        return products

    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        # å¦‚æœ XML è§£æå¤±è´¥ï¼Œæ‰“å°å‡ºæ¥çœ‹çœ‹å†…å®¹
        return []

def update_html(new_data):
    if not new_data: return
    try:
        with open("index.html", "r", encoding="utf-8") as f: content = f.read()
        
        js_data = ""
        for p in new_data:
            js_data += "                {\n"
            js_data += f"                    id: {p['id']}, platform: '{p['platform']}', title: '{p['title']}', price: '{p['price']}', sales: '{p['sales']}', score: {p['score']}, emoji: '{p['emoji']}',\n"
            js_data += f"                    aiReason: '{p['aiReason']}'\n"
            js_data += "                },\n"

        pattern = r"(// DATA_START\n)(.*?)(// DATA_END)"
        if re.search(pattern, content, re.DOTALL):
            new_content = re.sub(pattern, f"\\1{js_data}                \\3", content, flags=re.DOTALL)
            with open("index.html", "w", encoding="utf-8") as f: f.write(new_content)
            print("ğŸ‰ å›½å†…æ•°æ®æ›´æ–°æˆåŠŸï¼")
    except: pass

if __name__ == "__main__":
    data = fetch_domestic_data()
    update_html(data)
